{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "class bq_jobrunner :\n",
    "    \n",
    "    \n",
    "    def __init__(self,project_id: str,credentials_path: str,location: str):\n",
    "       \n",
    "        import os\n",
    "        self.project_id = project_id\n",
    "        self.location = location\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "        self.client = bigquery.Client()\n",
    "        self.jobs = {}\n",
    "        self.processed_jobs =[]\n",
    "        \n",
    "    def compose_query(self,query_id :int, sql: str, dest_dataset:str,\n",
    "                      dest_table:str,dependent_query: list =[],common_name=''):\n",
    "        job_config = bigquery.QueryJobConfig()\n",
    "        job_config.destination = self.client.dataset(dest_dataset).table(dest_table)\n",
    "        job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "        job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "        \n",
    "        job = {\n",
    "            \"query_id\"         : query_id\n",
    "            ,\"sql\"             : sql\n",
    "            ,\"job_config\"      : job_config\n",
    "            ,\"dependent_query\" : dependent_query\n",
    "            ,\"is_finished\"     : False\n",
    "            ,\"common_name\"     : common_name\n",
    "        }\n",
    "        \n",
    "        self.jobs[query_id] = job\n",
    "\n",
    "        \n",
    "        \n",
    "    def queue_jobs(self):\n",
    "        self.queue = []\n",
    "        #queue all jobs which has no dependency\n",
    "        for k,v in self.jobs.items():\n",
    "            dependent_queries = []\n",
    "            dependent_queries = set(v['dependent_query']) - set(self.processed_jobs)\n",
    "            if (v['is_finished'] == False) and (not dependent_queries):\n",
    "                self.queue.append(v['query_id'])\n",
    "\n",
    "    \n",
    "    def run_job(self,job_id):\n",
    "        job = self.jobs[job_id]\n",
    "        print('Running \"{0}\"(query_id :{1}) ...'.format(job[\"common_name\"],job[\"query_id\"]))\n",
    "        query_job = self.client.query(\n",
    "            job[\"sql\"],\n",
    "            location=self.location,\n",
    "            job_config=job[\"job_config\"])\n",
    "        query_job.result()\n",
    "        print('Query \"{}\" has been finished. {:.2f} GBs are processed.'\n",
    "                .format(job[\"common_name\"],query_job.total_bytes_processed/1073741824))\n",
    "        self.jobs[job_id][\"is_finished\"] = True\n",
    "        self.processed_jobs.append(job[\"query_id\"])\n",
    "        \n",
    "    def execute(self):\n",
    "        from joblib import Parallel, delayed\n",
    "        while len(self.jobs) != len(self.processed_jobs):\n",
    "            print(len(self.processed_jobs),\"jobs have been processed out of\",len(self.jobs),\"jobs.\")\n",
    "            self.queue_jobs()\n",
    "            for job_id in self.queue:\n",
    "                self.run_job(job_id)\n",
    "            \n",
    "        else:\n",
    "            print(\"Finished all jobs.\")\n",
    "            \n",
    "            \n",
    "    def render_graph(self):\n",
    "        from graphviz import Digraph\n",
    "        G = Digraph(format='png')\n",
    "        G.attr('node', shape='circle')\n",
    "\n",
    "        for j in self.jobs:\n",
    "            G.node(str(j), self.jobs[j]['common_name'])\n",
    "            \n",
    "        for j in self.jobs:\n",
    "            for d in self.jobs[j]['dependent_query']:\n",
    "               G.edge(str(d), str(j))\n",
    "\n",
    "        G.render(view = True)\n",
    "\n",
    "\n",
    "##TODO parallel processing\n",
    "\n",
    "#     def execute(self):\n",
    "#         from joblib import Parallel, delayed\n",
    "#         while len(self.jobs) != len(self.processed_jobs):\n",
    "#             print(len(self.processed_jobs),\"jobs have been processed out of\",len(self.jobs),\"jobs.\")\n",
    "#             self.queue_jobs()\n",
    "#             import copy\n",
    "            \n",
    "#             q = copy.deepcopy(self.queue)\n",
    "#             Parallel(n_jobs=2, verbose=10)([delayed(MulHelper(self, 'run_job'))(job_id) for job_id in q])\n",
    "            \n",
    "#         else:\n",
    "#             print(\"Finished all jobs.\")\n",
    "        \n",
    "        \n",
    "# class MulHelper(object):\n",
    "#     def __init__(self, cls, mtd_name):\n",
    "#         self.cls = cls\n",
    "#         self.mtd_name = mtd_name\n",
    "\n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return getattr(self.cls, self.mtd_name)(*args, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "1.0.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
